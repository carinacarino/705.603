{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Model Selection Analysis**: Transaction Fraud Detection\n",
    "\n",
    "### Carina Carino\n",
    "\n",
    "### 02/24/2024\n",
    "\n",
    " Analyze the performance of three candidate models of your choosing. Argue for which model you select using the criteria you design in . Report how the selected model's performance will influence the systems design."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b16f3ae9474d95a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install and Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67212b795836a367"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from scikit-learn) (3.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from xgboost) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn-intelex in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (2024.1.0)\n",
      "Requirement already satisfied: daal4py==2024.1.0 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from scikit-learn-intelex) (2024.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from scikit-learn-intelex) (1.4.1.post1)\n",
      "Requirement already satisfied: daal==2024.1.0 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from daal4py==2024.1.0->scikit-learn-intelex) (2024.1.0)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from daal4py==2024.1.0->scikit-learn-intelex) (1.26.4)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from daal==2024.1.0->daal4py==2024.1.0->scikit-learn-intelex) (2021.11.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from scikit-learn>=0.22->scikit-learn-intelex) (3.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Flask in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from Flask) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from Flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from Flask) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from Flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from Flask) (1.7.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from Flask) (7.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from click>=8.1.3->Flask) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from importlib-metadata>=3.6.0->Flask) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\carin\\pycharmprojects\\fraud_detection\\venv\\lib\\site-packages (from Jinja2>=3.1.2->Flask) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install xgboost\n",
    "!pip install scikit-learn-intelex\n",
    "!pip install Flask\n",
    "!pip install catboost\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearnex import patch_sklearn \n",
    "\n",
    "patch_sklearn()\n",
    "\n",
    "import calendar\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "pd.set_option(\"display.precision\", 2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-25T16:55:22.278963100Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Extraction and Transformation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c71861abccc4f15"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "data = pd.read_csv('../transactions.csv', header=[0], index_col=[0])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "data['trans_date_trans_time'] = pd.to_datetime(data['trans_date_trans_time'])\n",
    "data['trans_date'] = data['trans_date_trans_time'].dt.date\n",
    "data['trans_date'] = pd.to_datetime(data['trans_date'])\n",
    "data['dob']=pd.to_datetime(data['dob'])\n",
    "data[\"age\"] = data[\"trans_date\"]-data[\"dob\"]\n",
    "data[\"age\"] = data[\"age\"].astype('int64')\n",
    "data['trans_month'] = pd.DatetimeIndex(data['trans_date']).month\n",
    "data['trans_year'] = pd.DatetimeIndex(data['trans_date']).year\n",
    "data['month_name'] = data['trans_month'].apply(lambda x: calendar.month_abbr[x])\n",
    "data['lat_dist_diff'] = abs(round(data['merch_lat']-data['lat'],3))\n",
    "data['long_dist_diff'] = abs(round(data['merch_long']-data['long'],3))\n",
    "data['city_state'] = data['city'] + ', ' + data['state']\n",
    "\n",
    "data['trans_hour'] = data['trans_date_trans_time'].dt.hour\n",
    "data['trans_minute'] = data['trans_date_trans_time'].dt.minute\n",
    "\n",
    "data = data.drop(['cc_num','first','last','street','trans_num','trans_date_trans_time','city','lat','long','dob','merch_lat',\n",
    "'merch_long','trans_date','month_name','city', 'trans_year'],axis=1)\n",
    "\n",
    "data['city_state'] = label_encoder.fit_transform(data['city_state'])\n",
    "data['zip'] = label_encoder.fit_transform(data['zip'])\n",
    "data['job'] = label_encoder.fit_transform(data['job'])\n",
    "data['merchant'] = label_encoder.fit_transform(data['merchant'])\n",
    "data['sex'] = label_encoder.fit_transform(data['sex'])\n",
    "\n",
    "data =pd.get_dummies(data,columns=['category'],drop_first=True)\n",
    "data =pd.get_dummies(data,columns=['state'],drop_first=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T18:53:43.716155800Z",
     "start_time": "2024-02-25T18:53:34.020224500Z"
    }
   },
   "id": "97c9f5c0c1854272"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Splitting"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac28319e3d2c4f38"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X = data.drop(['is_fraud'], axis=1)\n",
    "y = data['is_fraud']  # Ensure y is a Series for compatibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale your data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T16:57:50.196092200Z",
     "start_time": "2024-02-25T16:57:45.837990200Z"
    }
   },
   "id": "e308b78d8233ae64"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a9af424a46036e0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### I. No Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8640e50c6049e838"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    368526\n",
      "           1       0.98      0.72      0.83      1953\n",
      "\n",
      "    accuracy                           1.00    370479\n",
      "   macro avg       0.99      0.86      0.91    370479\n",
      "weighted avg       1.00      1.00      1.00    370479\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Random Forest with default parameters\n",
    "rf_default = RandomForestClassifier(random_state=42)\n",
    "rf_default.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_default = rf_default.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred_default))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T17:06:38.093635200Z",
     "start_time": "2024-02-25T17:06:02.936965100Z"
    }
   },
   "id": "2c98befc2c3d58e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### II. With Class Weights"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6122641261a20e8d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97    368526\n",
      "           1       0.09      0.97      0.17      1953\n",
      "\n",
      "    accuracy                           0.95    370479\n",
      "   macro avg       0.55      0.96      0.57    370479\n",
      "weighted avg       1.00      0.95      0.97    370479\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with class weight balancing\n",
    "rf_balanced = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "rf_balanced.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_balanced = rf_balanced.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred_balanced))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T17:08:06.798744300Z",
     "start_time": "2024-02-25T17:07:26.594387300Z"
    }
   },
   "id": "e031568d077d215"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### III. With SMOTE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e92bd0264bf72f7"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    368526\n",
      "           1       0.86      0.81      0.83      1953\n",
      "\n",
      "    accuracy                           1.00    370479\n",
      "   macro avg       0.93      0.90      0.92    370479\n",
      "weighted avg       1.00      1.00      1.00    370479\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "\n",
    "# Define pipeline with SMOTE and Random Forest\n",
    "pipeline_smote = ImPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_smote.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_smote = pipeline_smote.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred_smote))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T17:12:29.934722700Z",
     "start_time": "2024-02-25T17:10:56.435367300Z"
    }
   },
   "id": "e40d8b29f80e1071"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IV. With Borderline SMOTE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8904233b2539915"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    368526\n",
      "           1       0.89      0.78      0.83      1953\n",
      "\n",
      "    accuracy                           1.00    370479\n",
      "   macro avg       0.95      0.89      0.92    370479\n",
      "weighted avg       1.00      1.00      1.00    370479\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# Define pipeline with Borderline SMOTE and Random Forest\n",
    "pipeline_bsmote = ImPipeline([\n",
    "    ('bsmote', BorderlineSMOTE(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_bsmote.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_bsmote = pipeline_bsmote.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred_bsmote))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T17:16:32.116232600Z",
     "start_time": "2024-02-25T17:14:57.418400400Z"
    }
   },
   "id": "18c5e93d1dc541c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a17a8cb442b9d33"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### I. No Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d26f21efbc1c9eed"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    368526\n",
      "           1       0.96      0.84      0.89      1953\n",
      "\n",
      "    accuracy                           1.00    370479\n",
      "   macro avg       0.98      0.92      0.95    370479\n",
      "weighted avg       1.00      1.00      1.00    370479\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# XGBoost with default parameters\n",
    "xgb_default = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_default.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_default = xgb_default.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred_default))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T17:26:02.032838500Z",
     "start_time": "2024-02-25T17:25:55.104730500Z"
    }
   },
   "id": "759c88bcd9b0e379"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### II. With Class Weights"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95522ea35ac1415b"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    368526\n",
      "           1       0.49      0.96      0.65      1953\n",
      "\n",
      "    accuracy                           0.99    370479\n",
      "   macro avg       0.74      0.98      0.82    370479\n",
      "weighted avg       1.00      0.99      1.00    370479\n"
     ]
    }
   ],
   "source": [
    "# Calculate scale_pos_weight\n",
    "# It's a good practice to set it as sum(negative instances) / sum(positive instances)\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# XGBoost with class weight balancing\n",
    "xgb_balanced = XGBClassifier(use_label_encoder=False, eval_metric='logloss', scale_pos_weight=scale_pos_weight, random_state=42)\n",
    "xgb_balanced.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_balanced = xgb_balanced.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred_balanced))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T17:25:38.464544800Z",
     "start_time": "2024-02-25T17:25:31.880506200Z"
    }
   },
   "id": "182bae9bd9455ef3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### III. With SMOTE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67837738af4f649d"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    368526\n",
      "           1       0.72      0.89      0.80      1953\n",
      "\n",
      "    accuracy                           1.00    370479\n",
      "   macro avg       0.86      0.94      0.90    370479\n",
      "weighted avg       1.00      1.00      1.00    370479\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "\n",
    "# Define pipeline with SMOTE and XGBoost\n",
    "pipeline_smote_xgb = ImPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_smote_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_smote = pipeline_smote_xgb.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred_smote))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T17:19:39.346204700Z",
     "start_time": "2024-02-25T17:19:26.469886700Z"
    }
   },
   "id": "419c4db040937c09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IV. With Borderline SMOTE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c6bdbc0fe2cd18"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    368526\n",
      "           1       0.80      0.86      0.83      1953\n",
      "\n",
      "    accuracy                           1.00    370479\n",
      "   macro avg       0.90      0.93      0.91    370479\n",
      "weighted avg       1.00      1.00      1.00    370479\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# Define pipeline with Borderline SMOTE and XGBoost\n",
    "pipeline_bsmote_xgb = ImPipeline([\n",
    "    ('bsmote', BorderlineSMOTE(random_state=42)),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_bsmote_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_bsmote = pipeline_bsmote_xgb.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred_bsmote))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T17:20:03.170748200Z",
     "start_time": "2024-02-25T17:19:44.722433900Z"
    }
   },
   "id": "8b297a9d1ff30534"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost with Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62074639733f020c"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Best parameters found:  {'colsample_bytree': 0.8, 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 1.0}\n",
      "Best recall found:  0.7929332294102366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'gamma': [0.5, 1, 1.5, 2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, scoring='recall', n_jobs=-1, cv=3, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best recall found: \", grid_search.best_score_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T17:51:14.180455500Z",
     "start_time": "2024-02-25T17:28:17.476962800Z"
    }
   },
   "id": "bbed60badc4b6874"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Catboost\n",
    "https://catboost.ai/en/docs/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a15b3c0f078f4c4e"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7373576\tbest: 0.7373576 (0)\ttotal: 282ms\tremaining: 9m 24s\n",
      "500:\ttest: 0.9989258\tbest: 0.9989258 (500)\ttotal: 5m 22s\tremaining: 16m 6s\n",
      "1000:\ttest: 0.9992824\tbest: 0.9992851 (986)\ttotal: 10m 46s\tremaining: 10m 45s\n",
      "1500:\ttest: 0.9994531\tbest: 0.9994537 (1496)\ttotal: 16m 17s\tremaining: 5m 24s\n",
      "1999:\ttest: 0.9994817\tbest: 0.9994833 (1985)\ttotal: 21m 40s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9994832724\n",
      "bestIteration = 1985\n",
      "\n",
      "Shrink model to first 1986 iterations.\n",
      "Accuracy: 0.9992874090029394\n",
      "Precision: 0.9768492377188029\n",
      "Recall: 0.8858166922683052\n",
      "F1 Score: 0.9291084854994629\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('../transactions.csv', header=[0], index_col=[0])\n",
    "\n",
    "\n",
    "data['trans_date_trans_time'] = pd.to_datetime(data['trans_date_trans_time'])\n",
    "data['trans_date'] = data['trans_date_trans_time'].dt.date\n",
    "data['trans_date'] = pd.to_datetime(data['trans_date'])\n",
    "data['dob']=pd.to_datetime(data['dob'])\n",
    "data[\"age\"] = data[\"trans_date\"]-data[\"dob\"]\n",
    "data[\"age\"] = data[\"age\"].astype('int64')\n",
    "data['trans_month'] = pd.DatetimeIndex(data['trans_date']).month\n",
    "data['trans_year'] = pd.DatetimeIndex(data['trans_date']).year\n",
    "data['month_name'] = data['trans_month'].apply(lambda x: calendar.month_abbr[x])\n",
    "data['lat_dist_diff'] = abs(round(data['merch_lat']-data['lat'],3))\n",
    "data['long_dist_diff'] = abs(round(data['merch_long']-data['long'],3))\n",
    "data['city_state'] = data['city'] + ', ' + data['state']\n",
    "\n",
    "data['trans_hour'] = data['trans_date_trans_time'].dt.hour\n",
    "data['trans_minute'] = data['trans_date_trans_time'].dt.minute\n",
    "\n",
    "data['time_category'] = pd.cut(data['trans_hour'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "data = data.drop(['cc_num','first','last','street','trans_num','trans_date_trans_time','city','lat','long','dob','merch_lat',\n",
    "'merch_long','trans_date','month_name','city'],axis=1)\n",
    "\n",
    "# Define categorical features\n",
    "categorical_features = ['city_state', 'zip', 'job', 'merchant', 'sex', 'category', 'state', 'time_category']\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data.drop(['is_fraud'], axis=1)\n",
    "y = data['is_fraud']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize CatBoostClassifier\n",
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.1,\n",
    "    depth=8,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    use_best_model=True,\n",
    "    random_seed=42,\n",
    "    verbose=500\n",
    ")\n",
    "\n",
    "# Create a Pool object for the training and test data\n",
    "train_pool = Pool(X_train, y_train, cat_features=categorical_features)\n",
    "test_pool = Pool(X_test, y_test, cat_features=categorical_features)\n",
    "\n",
    "# Train the model\n",
    "catboost_model.fit(train_pool, eval_set=test_pool)\n",
    "\n",
    "# Predict\n",
    "y_pred = catboost_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T19:20:02.640817300Z",
     "start_time": "2024-02-25T18:58:01.617051500Z"
    }
   },
   "id": "8f55ca78b86b83d1"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Feature  Importance\n",
      "2              amt       22.04\n",
      "1         category       19.69\n",
      "15      trans_hour       11.06\n",
      "9              age        8.70\n",
      "8        unix_time        7.83\n",
      "17   time_category        4.99\n",
      "6         city_pop        4.46\n",
      "0         merchant        3.69\n",
      "16    trans_minute        2.47\n",
      "13  long_dist_diff        2.41\n",
      "7              job        2.24\n",
      "12   lat_dist_diff        2.21\n",
      "3              sex        1.93\n",
      "10     trans_month        1.84\n",
      "5              zip        1.82\n",
      "4            state        1.48\n",
      "14      city_state        1.13\n",
      "11      trans_year        0.03\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance scores\n",
    "feature_importance = catboost_model.get_feature_importance(train_pool)\n",
    "\n",
    "# Create a DataFrame to display feature importance scores\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T19:37:44.535931200Z",
     "start_time": "2024-02-25T19:36:14.848736500Z"
    }
   },
   "id": "ada82373ca19e990"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n",
    "{\n",
    "    \"trans_date_trans_time\": \"2022-10-12 14:32:21\",\n",
    "    \"cc_num\": 2703186189652095,\n",
    "    \"merchant\": \"fraud_Kilback LLC\",\n",
    "    \"category\": \"shopping_net\",\n",
    "    \"amt\": 105.89,\n",
    "    \"first\": \"John\",\n",
    "    \"last\": \"Doe\",\n",
    "    \"sex\": \"M\",\n",
    "    \"street\": \"123 Elm Street\",\n",
    "    \"city\": \"Washington\",\n",
    "    \"state\": \"DC\",\n",
    "    \"zip\": 62704,\n",
    "    \"lat\": 39.7817,\n",
    "    \"long\": -89.6508,\n",
    "    \"city_pop\": 116250,\n",
    "    \"job\": \"IT trainer\",\n",
    "    \"dob\": \"1990-05-19\",\n",
    "    \"trans_num\": \"e9c2d8a2bb342bc446df5f578cddf8ac\",\n",
    "    \"unix_time\": 1634055141,\n",
    "    \"merch_lat\": 39.7957,\n",
    "    \"merch_long\": -89.6433\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T02:08:35.782028500Z"
    }
   },
   "id": "20bed66f3129b6ff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NOTE:\n",
    "\n",
    "The catboost model performed the best with 97% precision and 88% recall. However, since catboost does not require scaling and supports categorical features (meaning we do not have to scale the numeric features and encode the categorical features) and this case study focuses heavily on feature transformations, XGBoost with no hyperparameters is chosen instead to demonstrate proficiency in feature engineering techniques. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "376debf272889830"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e01bf34e0c0854d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
